{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03d6fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import zipfile\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from types import MethodType\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33b1d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # for multi-GPU setups\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ec23d604",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e54964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from types import MethodType\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def wrap_vit_blocks_dino(model):\n",
    "    activations = {}\n",
    "    original_blocks = model.blocks  \n",
    "\n",
    "    for i, block in enumerate(original_blocks):\n",
    "        def make_custom_forward(orig_forward, layer_name):\n",
    "            def custom_forward(self, x):\n",
    "                out = orig_forward(x)\n",
    "                activations[layer_name] = out.detach()\n",
    "                return out\n",
    "            return custom_forward\n",
    "\n",
    "        block.forward = MethodType(make_custom_forward(block.forward, f\"layer_{i}\"), block)\n",
    "\n",
    "    return activations\n",
    "\n",
    "def logit_lens_analysis_dino(activations, model, final_cls_token, temperature=1.0, true_class_idx=None):\n",
    "    distances = {}\n",
    "    predictions = {}\n",
    "    true_class_probs = []\n",
    "    first_top_class_probs = []\n",
    "    last_layer_top_class_probs = []\n",
    "    random_class_probs = []\n",
    "    kl_divergence = []\n",
    "\n",
    "    first_layer_top_class = None\n",
    "    last_layer_top_class = None\n",
    "\n",
    "    # Find last layer name (assuming activations are ordered)\n",
    "    last_layer_name = list(activations.keys())[-1]\n",
    "\n",
    "    # Get the probs at the last layer to determine top class there\n",
    "    last_layer_activ = activations[last_layer_name]\n",
    "    last_cls_token = last_layer_activ[:, 0, :]\n",
    "    last_normed = model.norm(last_cls_token)\n",
    "    last_logits = model.head(last_normed)\n",
    "    last_probs = F.softmax(last_logits / temperature, dim=-1)\n",
    "    last_top_prob, last_top_class = torch.max(last_probs, dim=-1)\n",
    "    last_layer_top_class = int(last_top_class[0].cpu().item())\n",
    "\n",
    "    #last_probs -> probabilities at the last layer\n",
    "\n",
    "    for i, (name, x) in enumerate(activations.items()):\n",
    "        cls_token = x[:, 0, :]\n",
    "        normed = model.norm(cls_token)\n",
    "\n",
    "        similarity = F.cosine_similarity(normed, final_cls_token, dim=-1)\n",
    "        distances[name] = similarity.detach().cpu().item()\n",
    "\n",
    "        logits = model.head(normed)\n",
    "        probs = F.softmax(logits / temperature, dim=-1)\n",
    "\n",
    "        # calculate KL divergence with respect to the last layer\n",
    "        if i == len(activations) - 1:\n",
    "            kl_div = torch.zeros(logits.shape[-1], device=logits.device)\n",
    "        else:\n",
    "            last_probs = F.softmax(last_logits / temperature, dim=-1)\n",
    "            kl_div = F.kl_div(probs.log(), last_probs, reduction='none').sum(dim=-1)\n",
    "\n",
    "        top_prob, top_class = torch.max(probs, dim=-1)\n",
    "        predictions[f\"{name}_label\"] = int(top_class[0].cpu().item())\n",
    "        predictions[f\"{name}_prob\"] = float(top_prob[0].cpu().item())\n",
    "\n",
    "        random_class_idx = np.random.randint(0, logits.shape[-1] - 1)\n",
    "        if random_class_idx is not None:\n",
    "            random_class_probs.append(float(probs[0, random_class_idx].item()))\n",
    "\n",
    "        if true_class_idx is not None:\n",
    "            true_class_probs.append(float(probs[0, true_class_idx].item()))\n",
    "        else:\n",
    "            true_class_probs[name] = None\n",
    "\n",
    "        if i == 0:\n",
    "            first_layer_top_class = int(top_class[0].cpu().item())\n",
    "\n",
    "        if first_layer_top_class is not None:\n",
    "           first_top_class_probs.append(float(probs[0, first_layer_top_class].item()))\n",
    "        else:\n",
    "            first_top_class_probs[name] = None\n",
    "    \n",
    "        if last_layer_top_class is not None:\n",
    "            last_layer_top_class_probs.append(float(probs[0, last_layer_top_class].item()))\n",
    "        else:\n",
    "            last_layer_top_class_probs.append(None)\n",
    "\n",
    "        if kl_div is not None:\n",
    "            kl_divergence.append(float(kl_div[0].cpu().item()))\n",
    "    \n",
    "\n",
    "    return distances, predictions, true_class_probs, first_top_class_probs, last_layer_top_class_probs, random_class_probs, random_class_idx, kl_divergence\n",
    "\n",
    "\n",
    "def load_tiny_imagenet_labels(path=\"tiny-imagenet-200/words.txt\"):\n",
    "    wnid_to_label = {}\n",
    "    with open(path, \"r\") as f:\n",
    "        for line in f:\n",
    "            wnid, label = line.strip().split(\"\\t\")\n",
    "            wnid_to_label[wnid] = label\n",
    "    return wnid_to_label\n",
    "\n",
    "def perform_logit_lens_analysis(model, dataset, device,\n",
    "                                cosine_path=\"logit_lens_results/cosine_similarity.csv\",\n",
    "                                preds_path=\"logit_lens_results/predictions.csv\",\n",
    "                                true_probs_path = \"logit_lens_results/true_class_probs.csv\",\n",
    "                                first_top_probs_path = \"logit_lens_results/first_top_class_probs.csv\",\n",
    "                                random_probs_path = \"logit_lens_results/random_class_probs.csv\",\n",
    "                                last_layer_probs_path = \"logit_lens_results/last_layer_top_class_probs.csv\",\n",
    "                                kl_divergence_path = \"logit_lens_results/kl_divergence.csv\"):\n",
    "    model.eval()\n",
    "    idx_to_wnid = {v: k for k, v in dataset.dataset.class_to_idx.items()}\n",
    "\n",
    "    os.makedirs(\"logit_lens_results\", exist_ok=True)\n",
    "\n",
    "    activations = wrap_vit_blocks_dino(model)  # sets up forward hooks to save to model.activations\n",
    "    headers = [f\"layer_{i}\" for i in range(len(model.blocks))]\n",
    "    wnid_to_label = load_tiny_imagenet_labels()\n",
    "\n",
    "    for image_idx, (image, label) in enumerate(dataset):\n",
    "        image = image.unsqueeze(0).to(device)\n",
    "        \n",
    "        true_wnid = idx_to_wnid[label] \n",
    "        true_label = wnid_to_label.get(true_wnid, \"\") \n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.activations = {}  # clear previous activations\n",
    "            features = model.forward_features(image)     \n",
    "            cls_token = features[:, 0, :]  # [1, 384]\n",
    "            final_cls_token = model.norm(cls_token)      # [1, 384]\n",
    "            final_output = model.head(final_cls_token)    # [1, num_classes]\n",
    "\n",
    "            true_class_idx = label.item() if hasattr(label, 'item') else int(label)\n",
    "            distances, predictions, true_class_probs, first_top_class_probs, last_layer_probs, random_class_probs, random_idx, kl_div = logit_lens_analysis_dino(\n",
    "                activations, model, final_cls_token, true_class_idx=true_class_idx)\n",
    "            \n",
    "        # --- KL DIVERGENCE FILE ---\n",
    "        os.makedirs(os.path.dirname(kl_divergence_path), exist_ok=True)\n",
    "        kl_header = ['Image', 'True_WNID', 'True_Label'] + headers\n",
    "        write_header = not os.path.exists(kl_divergence_path) or os.path.getsize(kl_divergence_path) == 0\n",
    "        with open(kl_divergence_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            if write_header:\n",
    "                writer.writerow(kl_header)\n",
    "            kl_row = [f\"Image_{image_idx + 1}\", true_wnid, true_label] + kl_div\n",
    "            writer.writerow(kl_row)\n",
    "\n",
    "\n",
    "        # --- COSINE FILE ---\n",
    "        os.makedirs(os.path.dirname(cosine_path), exist_ok=True)\n",
    "        cosine_header = ['Image', 'True_WNID', 'True_Label'] + headers\n",
    "        write_header = not os.path.exists(cosine_path) or os.path.getsize(cosine_path) == 0\n",
    "        with open(cosine_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            if write_header:\n",
    "                writer.writerow(cosine_header)\n",
    "            cosine_row = [f\"Image_{image_idx + 1}\", true_wnid, true_label] + \\\n",
    "                        [distances[layer] for layer in headers]\n",
    "            writer.writerow(cosine_row)\n",
    "\n",
    "        # --- PREDICTIONS FILE ---\n",
    "        os.makedirs(os.path.dirname(preds_path), exist_ok=True) \n",
    "        pred_header = ['Image', 'True_WNID', 'True_Label'] + \\\n",
    "            [f\"{layer}_label\" for layer in headers] + \\\n",
    "            [f\"{layer}_prob\" for layer in headers]\n",
    "        write_header = not os.path.exists(preds_path) or os.path.getsize(preds_path) == 0\n",
    "        with open(preds_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            if write_header:\n",
    "                writer.writerow(pred_header)\n",
    "            pred_probs = [predictions[f\"{layer}_prob\"] for layer in headers]\n",
    "            pred_indices = [predictions[f\"{layer}_label\"] for layer in headers]\n",
    "            pred_wnids = [idx_to_wnid[int(idx)] for idx in pred_indices]\n",
    "            pred_labels = [wnid_to_label.get(wnid, wnid) for wnid in pred_wnids]\n",
    "\n",
    "            pred_row = [f\"Image_{image_idx + 1}\", true_wnid, true_label] + pred_labels + pred_probs\n",
    "            writer.writerow(pred_row)\n",
    "\n",
    "        # --- TRUE CLASS PROBS FILE ---\n",
    "        os.makedirs(os.path.dirname(true_probs_path), exist_ok=True)\n",
    "        true_header = ['Image', 'True_WNID', 'True_Label'] + headers\n",
    "\n",
    "        write_header = not os.path.exists(true_probs_path) or os.path.getsize(true_probs_path) == 0\n",
    "        with open(true_probs_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            if write_header:\n",
    "                writer.writerow(true_header)\n",
    "            true_probs_row = [f\"Image_{image_idx + 1}\", true_wnid, true_label] + true_class_probs\n",
    "\n",
    "            writer.writerow(true_probs_row)\n",
    "\n",
    "        # --- FIRST PREDICTED CLASS PROBS FILE ---\n",
    "        os.makedirs(os.path.dirname(first_top_probs_path), exist_ok=True)\n",
    "        first_top_header = ['Image', 'True_WNID', 'True_Label', 'First_Top1_WNID', 'First_Top1_Label'] + headers\n",
    "\n",
    "        # Get first top class info\n",
    "        first_top_idx = predictions.get(f\"{headers[0]}_label\", None)\n",
    "        first_top_wnid = idx_to_wnid.get(first_top_idx, \"N/A\")\n",
    "        first_top_label = wnid_to_label.get(first_top_wnid, \"N/A\")\n",
    "\n",
    "        write_header = not os.path.exists(first_top_probs_path) or os.path.getsize(first_top_probs_path) == 0\n",
    "        with open(first_top_probs_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            if write_header:\n",
    "                writer.writerow(first_top_header)\n",
    "            first_probs_row = [f\"Image_{image_idx + 1}\", true_wnid, true_label, first_top_wnid, first_top_label] + first_top_class_probs  \n",
    "            writer.writerow(first_probs_row)\n",
    "\n",
    "        # --- RANDOM CLASS PROBS FILE ---\n",
    "        os.makedirs(os.path.dirname(random_probs_path), exist_ok=True)\n",
    "        first_top_header = ['Image', 'True_WNID', 'True_Label', 'Random_WNID', 'Random_Label'] + headers\n",
    "\n",
    "        random_wnid = idx_to_wnid.get(random_idx, \"N/A\")\n",
    "        random_label = wnid_to_label.get(random_wnid, \"N/A\")\n",
    "\n",
    "        write_header = not os.path.exists(random_probs_path) or os.path.getsize(first_top_probs_path) == 0\n",
    "        with open(random_probs_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            if write_header:\n",
    "                writer.writerow(first_top_header)\n",
    "            first_probs_row = [f\"Image_{image_idx + 1}\", true_wnid, true_label, random_wnid, random_label] + random_class_probs  \n",
    "            writer.writerow(first_probs_row)\n",
    "\n",
    "        # --- LAST LAYER TOP CLASS PROBS FILE ---\n",
    "        os.makedirs(os.path.dirname(last_layer_probs_path), exist_ok=True)\n",
    "        last_layer_header = ['Image', 'True_WNID', 'True_Label', 'Last_Top1_WNID', 'Last_Top1_Label'] + headers\n",
    "\n",
    "        last_layer_top_idx = predictions.get(f\"{headers[-1]}_label\", None)\n",
    "        last_layer_top_wnid = idx_to_wnid.get(last_layer_top_idx, \"N/A\")\n",
    "        last_layer_top_label = wnid_to_label.get(last_layer_top_wnid, \"N/A\")\n",
    "        write_header = not os.path.exists(last_layer_probs_path) or os.path.getsize(last_layer_probs_path) == 0\n",
    "        with open(last_layer_probs_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            if write_header:\n",
    "                writer.writerow(last_layer_header)\n",
    "            last_probs_row = [f\"Image_{image_idx + 1}\", true_wnid, true_label, last_layer_top_wnid, last_layer_top_label] + last_layer_probs  \n",
    "            writer.writerow(last_probs_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "763b603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Config\n",
    "RANDOM_SEED = 42\n",
    "SUBSET_FRACTION = 0.1  # 0.05 for 5%, 0.1 for 10%\n",
    "BATCH_SIZE = 64\n",
    "VAL_FRACTION = 0.1 \n",
    "\n",
    "# Transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "                         std=[0.26862954, 0.26130258, 0.27577711]),\n",
    "])\n",
    "\n",
    "# Load full dataset\n",
    "train_dir = os.path.join(\"./tiny-imagenet-200\", \"train\")\n",
    "full_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "\n",
    "test_dir = os.path.join(\"./tiny-imagenet-200\", \"test\")\n",
    "full_test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "class_indices = defaultdict(list)\n",
    "for idx, (_, label) in enumerate(full_dataset.samples):\n",
    "    class_indices[label].append(idx)\n",
    "\n",
    "# Stratified sampling\n",
    "rng = random.Random(RANDOM_SEED)\n",
    "train_indices = []\n",
    "val_indices = []\n",
    "\n",
    "for label, indices in class_indices.items():\n",
    "    rng.shuffle(indices)  # shuffle within each class\n",
    "    \n",
    "    n_total = len(indices)\n",
    "    n_train = int(SUBSET_FRACTION * n_total)\n",
    "    n_val = int(VAL_FRACTION * n_total)\n",
    "\n",
    "    # ensure at least 1 example per class\n",
    "    n_train = max(n_train, 1)\n",
    "    n_val = max(n_val, 1)\n",
    "\n",
    "    # Make sure we don't go out of bounds\n",
    "    available = indices[:n_train + n_val]\n",
    "    train_indices.extend(available[:n_train])\n",
    "    val_indices.extend(available[n_train:n_train + n_val])\n",
    "\n",
    "# Sort for reproducibility\n",
    "train_indices = sorted(train_indices)\n",
    "val_indices = sorted(val_indices)\n",
    "\n",
    "# Create subsets\n",
    "train_subset = Subset(full_dataset, train_indices)\n",
    "val_subset = Subset(full_dataset, val_indices)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1af825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 10.8985 - Acc: 0.0010\n",
      "Epoch 2/10 - Loss: 3.7338 - Acc: 0.2844\n",
      "Epoch 3/10 - Loss: 2.5257 - Acc: 0.4950\n",
      "Epoch 4/10 - Loss: 1.8642 - Acc: 0.6040\n",
      "Epoch 5/10 - Loss: 1.4702 - Acc: 0.6835\n",
      "Epoch 6/10 - Loss: 1.1389 - Acc: 0.7480\n",
      "Epoch 7/10 - Loss: 0.9130 - Acc: 0.8041\n",
      "Epoch 8/10 - Loss: 0.7275 - Acc: 0.8446\n",
      "Epoch 9/10 - Loss: 0.5890 - Acc: 0.8777\n",
      "Epoch 10/10 - Loss: 0.4900 - Acc: 0.9046\n",
      "Model saved to vit_dino_finetuned.pth\n"
     ]
    }
   ],
   "source": [
    "# import torch\n",
    "# import torch.nn as nn\n",
    "# import torch.optim as optim\n",
    "# from torch.utils.data import DataLoader\n",
    "# import timm\n",
    "# from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "# device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "# num_classes = 200\n",
    "# batch_size = 32\n",
    "# epochs = 10\n",
    "# lr = 0.001\n",
    "\n",
    "\n",
    "# train_transform = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "# ])\n",
    "\n",
    "# val_transform = transforms.Compose([\n",
    "#     transforms.Resize(256),\n",
    "#     transforms.CenterCrop(224),\n",
    "#     transforms.ToTensor(),\n",
    "#     transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "# ])\n",
    "\n",
    "\n",
    "# model = timm.create_model('vit_small_patch16_224.dino', pretrained=True)\n",
    "\n",
    "# for param in model.parameters():\n",
    "#     param.requires_grad = False\n",
    "\n",
    "# num_features = model.num_features \n",
    "\n",
    "# model.head = nn.Linear(model.num_features, num_classes)\n",
    "# for param in model.head.parameters():\n",
    "#     param.requires_grad = True\n",
    "\n",
    "# model = model.to(device)\n",
    "\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# optimizer = optim.Adam(model.head.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "# for epoch in range(epochs):\n",
    "#     model.train()\n",
    "#     total_loss = 0\n",
    "#     correct = 0\n",
    "#     total = 0\n",
    "    \n",
    "#     for images, labels in val_loader:\n",
    "#         images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "#         outputs = model(images)\n",
    "#         loss = criterion(outputs, labels)\n",
    "        \n",
    "#         optimizer.zero_grad()\n",
    "#         loss.backward()\n",
    "#         optimizer.step()\n",
    "        \n",
    "#         total_loss += loss.item() * images.size(0)\n",
    "#         _, predicted = outputs.max(1)\n",
    "#         correct += predicted.eq(labels).sum().item()\n",
    "#         total += labels.size(0)\n",
    "\n",
    "#     train_acc = correct / total\n",
    "#     train_loss = total_loss / total\n",
    "#     print(f\"Epoch {epoch+1}/{epochs} - Loss: {train_loss:.4f} - Acc: {train_acc:.4f}\")\n",
    "\n",
    "# model.eval()\n",
    "\n",
    "# model_path = \"vit_dino_finetuned.pth\"\n",
    "# torch.save(model.state_dict(), model_path)\n",
    "# print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d3c1a5cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import timm\n",
    "num_classes = 200\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "model = timm.create_model('vit_small_patch16_224.dino', pretrained=False) \n",
    "num_features = model.num_features \n",
    "model.head = nn.Linear(model.num_features, num_classes)\n",
    "state_dict = torch.load(\"vit_dino_finetuned.pth\", map_location=\"cpu\") \n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "24d8edc4",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mperform_logit_lens_analysis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_subset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mcosine_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_lens_results/DINO_lp/cosine_similarity.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mpreds_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_lens_results/DINO_lp/predictions.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      6\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mtrue_probs_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_lens_results/DINO_lp/true_class_probs.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      7\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mfirst_top_probs_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_lens_results/DINO_lp/first_top_class_probs.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      8\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mrandom_probs_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_lens_results/DINO_lp/random_class_probs.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m      9\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mlast_layer_probs_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_lens_results/DINO_lp/last_layer_top_class_probs.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[0;32m     10\u001b[0m \u001b[43m                            \u001b[49m\u001b[43mkl_divergence_path\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mlogit_lens_results/DINO_lp/kl_divergence.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[10], line 137\u001b[0m, in \u001b[0;36mperform_logit_lens_analysis\u001b[1;34m(model, dataset, device, cosine_path, preds_path, true_probs_path, first_top_probs_path, random_probs_path, last_layer_probs_path, kl_divergence_path)\u001b[0m\n\u001b[0;32m    135\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m    136\u001b[0m     model\u001b[38;5;241m.\u001b[39mactivations \u001b[38;5;241m=\u001b[39m {}  \u001b[38;5;66;03m# clear previous activations\u001b[39;00m\n\u001b[1;32m--> 137\u001b[0m     features \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimage\u001b[49m\u001b[43m)\u001b[49m     \n\u001b[0;32m    138\u001b[0m     cls_token \u001b[38;5;241m=\u001b[39m features[:, \u001b[38;5;241m0\u001b[39m, :]  \u001b[38;5;66;03m# [1, 384]\u001b[39;00m\n\u001b[0;32m    139\u001b[0m     final_cls_token \u001b[38;5;241m=\u001b[39m model\u001b[38;5;241m.\u001b[39mnorm(cls_token)      \u001b[38;5;66;03m# [1, 384]\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Zosia\\.conda\\envs\\bhl\\Lib\\site-packages\\timm\\models\\vision_transformer.py:744\u001b[0m, in \u001b[0;36mVisionTransformer.forward_features\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    742\u001b[0m     x \u001b[38;5;241m=\u001b[39m checkpoint_seq(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mblocks, x)\n\u001b[0;32m    743\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 744\u001b[0m     x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mblocks\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    745\u001b[0m x \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm(x)\n\u001b[0;32m    746\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Zosia\\.conda\\envs\\bhl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Zosia\\.conda\\envs\\bhl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Zosia\\.conda\\envs\\bhl\\Lib\\site-packages\\torch\\nn\\modules\\container.py:250\u001b[0m, in \u001b[0;36mSequential.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[0;32m    249\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[1;32m--> 250\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    251\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\Zosia\\.conda\\envs\\bhl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Zosia\\.conda\\envs\\bhl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "Cell \u001b[1;32mIn[10], line 19\u001b[0m, in \u001b[0;36mwrap_vit_blocks_dino.<locals>.make_custom_forward.<locals>.custom_forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 19\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43morig_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     activations[layer_name] \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "Cell \u001b[1;32mIn[4], line 19\u001b[0m, in \u001b[0;36mwrap_vit_blocks_dino.<locals>.make_custom_forward.<locals>.custom_forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcustom_forward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x):\n\u001b[1;32m---> 19\u001b[0m     out \u001b[38;5;241m=\u001b[39m \u001b[43morig_forward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m     activations[layer_name] \u001b[38;5;241m=\u001b[39m out\u001b[38;5;241m.\u001b[39mdetach()\n\u001b[0;32m     21\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m out\n",
      "File \u001b[1;32mc:\\Users\\Zosia\\.conda\\envs\\bhl\\Lib\\site-packages\\timm\\models\\vision_transformer.py:165\u001b[0m, in \u001b[0;36mBlock.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m    164\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[1;32m--> 165\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path1(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mls1(\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m))\n\u001b[0;32m    166\u001b[0m     x \u001b[38;5;241m=\u001b[39m x \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdrop_path2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mls2(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnorm2(x))))\n\u001b[0;32m    167\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m x\n",
      "File \u001b[1;32mc:\\Users\\Zosia\\.conda\\envs\\bhl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Zosia\\.conda\\envs\\bhl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Zosia\\.conda\\envs\\bhl\\Lib\\site-packages\\timm\\models\\vision_transformer.py:87\u001b[0m, in \u001b[0;36mAttention.forward\u001b[1;34m(self, x)\u001b[0m\n\u001b[0;32m     85\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, x: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m     86\u001b[0m     B, N, C \u001b[38;5;241m=\u001b[39m x\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m---> 87\u001b[0m     qkv \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mqkv\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mreshape(B, N, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mnum_heads, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhead_dim)\u001b[38;5;241m.\u001b[39mpermute(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m0\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m4\u001b[39m)\n\u001b[0;32m     88\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m qkv\u001b[38;5;241m.\u001b[39munbind(\u001b[38;5;241m0\u001b[39m)\n\u001b[0;32m     89\u001b[0m     q, k \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mq_norm(q), \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mk_norm(k)\n",
      "File \u001b[1;32mc:\\Users\\Zosia\\.conda\\envs\\bhl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1739\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1737\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1738\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1739\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Zosia\\.conda\\envs\\bhl\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1750\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1745\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1746\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1747\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1748\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1749\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1750\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1752\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1753\u001b[0m called_always_called_hooks \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m()\n",
      "File \u001b[1;32mc:\\Users\\Zosia\\.conda\\envs\\bhl\\Lib\\site-packages\\torch\\nn\\modules\\linear.py:125\u001b[0m, in \u001b[0;36mLinear.forward\u001b[1;34m(self, input)\u001b[0m\n\u001b[0;32m    124\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m--> 125\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "perform_logit_lens_analysis(model=model,\n",
    "                            dataset=train_subset, \n",
    "                            device=device, \n",
    "                            cosine_path=\"logit_lens_results/DINO_lp/cosine_similarity.csv\", \n",
    "                            preds_path=\"logit_lens_results/DINO_lp/predictions.csv\",\n",
    "                            true_probs_path = \"logit_lens_results/DINO_lp/true_class_probs.csv\",\n",
    "                            first_top_probs_path = \"logit_lens_results/DINO_lp/first_top_class_probs.csv\",\n",
    "                            random_probs_path = \"logit_lens_results/DINO_lp/random_class_probs.csv\",\n",
    "                            last_layer_probs_path = \"logit_lens_results/DINO_lp/last_layer_top_class_probs.csv\",\n",
    "                            kl_divergence_path = \"logit_lens_results/DINO_lp/kl_divergence.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710e38f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "distances = pd.read_csv(\"logit_lens_results/DINO_lp/cosine_similarity.csv\")\n",
    "predictions = pd.read_csv(\"logit_lens_results/DINO_lp/predictions.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

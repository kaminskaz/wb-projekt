{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "03d6fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import random\n",
    "import zipfile\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from types import MethodType\n",
    "from collections import defaultdict\n",
    "\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import clip\n",
    "from PIL import Image\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "33b1d773",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_all_seeds(seed: int = 42):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)  # for multi-GPU setups\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ec23d604",
   "metadata": {},
   "outputs": [],
   "source": [
    "set_all_seeds(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57e54964",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from types import MethodType\n",
    "import os\n",
    "import csv\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "\n",
    "def wrap_vit_blocks_dino(model):\n",
    "    activations = {}\n",
    "    original_blocks = model.blocks  \n",
    "\n",
    "    for i, block in enumerate(original_blocks):\n",
    "        def make_custom_forward(orig_forward, layer_name):\n",
    "            def custom_forward(self, x):\n",
    "                out = orig_forward(x)\n",
    "                activations[layer_name] = out.detach()\n",
    "                return out\n",
    "            return custom_forward\n",
    "\n",
    "        block.forward = MethodType(make_custom_forward(block.forward, f\"layer_{i}\"), block)\n",
    "\n",
    "    return activations\n",
    "\n",
    "def logit_lens_analysis_dino(activations, model, final_cls_token, temperature=1.0):\n",
    "    distances = {}\n",
    "    predictions = {}\n",
    "\n",
    "    for name, x in activations.items():\n",
    "        cls_token = x[:, 0, :]  # shape: [1, 384]\n",
    "        normed = model.norm(cls_token)  # shape: [1, 384]\n",
    "        \n",
    "        # Cosine similarity to final layer CLS token\n",
    "        similarity = F.cosine_similarity(normed, final_cls_token, dim=-1)\n",
    "        distances[name] = similarity.detach().cpu().item()\n",
    "\n",
    "        logits = model.head(normed)  # shape: [1, num_classes]\n",
    "        probs = F.softmax(logits / temperature, dim=-1)\n",
    "        top_prob, top_class = torch.max(probs, dim=-1)\n",
    "        predictions[f\"{name}_label\"] = int(top_class[0].cpu().item())\n",
    "        predictions[f\"{name}_prob\"] = float(top_prob[0].cpu().item())\n",
    "\n",
    "    return distances, predictions\n",
    "\n",
    "\n",
    "def perform_logit_lens_analysis(model, dataset, device,\n",
    "                                cosine_path=\"logit_lens_results/cosine_similarity.csv\",\n",
    "                                preds_path=\"logit_lens_results/predictions.csv\"):\n",
    "    import csv\n",
    "    model.eval()\n",
    "    os.makedirs(\"logit_lens_results\", exist_ok=True)\n",
    "\n",
    "    activations = wrap_vit_blocks_dino(model)  # sets up forward hooks to save to model.activations\n",
    "    headers = [f\"layer_{i}\" for i in range(len(model.blocks))]\n",
    "\n",
    "    for image_idx, (image, label) in enumerate(dataset):\n",
    "        image = image.unsqueeze(0).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            model.activations = {}  # clear previous activations\n",
    "            features = model.forward_features(image)     \n",
    "            cls_token = features[:, 0, :]  # [1, 384]\n",
    "            final_cls_token = model.norm(cls_token)      # [1, 384]\n",
    "            logits = model.head(final_cls_token)         # [1, num_classes]\n",
    "\n",
    "            # Now use logit lens on intermediate CLS tokens\n",
    "            distances, predictions = logit_lens_analysis_dino(\n",
    "                activations,  # captured during forward\n",
    "                model,\n",
    "                final_cls_token     # this is what should be compared against\n",
    "            )\n",
    "\n",
    "        os.makedirs(os.path.dirname(cosine_path), exist_ok=True)\n",
    "        os.makedirs(os.path.dirname(preds_path), exist_ok=True) \n",
    "\n",
    "        # Write cosine similarity CSV\n",
    "        cosine_header = ['Image'] + headers\n",
    "        write_header = not os.path.exists(cosine_path) or os.path.getsize(cosine_path) == 0\n",
    "        with open(cosine_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            if write_header:\n",
    "                writer.writerow(cosine_header)\n",
    "            cosine_row = [f\"Image_{image_idx + 1}\"] + [distances[layer] for layer in headers]\n",
    "            writer.writerow(cosine_row)\n",
    "\n",
    "        # Write prediction CSV\n",
    "        pred_header = ['Image'] + [f\"{layer}_label\" for layer in headers] + [f\"{layer}_prob\" for layer in headers]\n",
    "        write_header = not os.path.exists(preds_path) or os.path.getsize(preds_path) == 0\n",
    "        with open(preds_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            if write_header:\n",
    "                writer.writerow(pred_header)\n",
    "            pred_labels = [predictions[f\"{layer}_label\"] for layer in headers]\n",
    "            pred_probs = [predictions[f\"{layer}_prob\"] for layer in headers]\n",
    "            pred_row = [f\"Image_{image_idx + 1}\"] + pred_labels + pred_probs\n",
    "            writer.writerow(pred_row)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "763b603c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Config\n",
    "RANDOM_SEED = 42\n",
    "SUBSET_FRACTION = 0.1  # 0.05 for 5%, 0.1 for 10%\n",
    "BATCH_SIZE = 64\n",
    "VAL_FRACTION = 0.1 \n",
    "\n",
    "# Transformation\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "                         std=[0.26862954, 0.26130258, 0.27577711]),\n",
    "])\n",
    "\n",
    "# Load full dataset\n",
    "train_dir = os.path.join(\"./tiny-imagenet-200\", \"train\")\n",
    "full_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "\n",
    "test_dir = os.path.join(\"./tiny-imagenet-200\", \"test\")\n",
    "full_test_dataset = datasets.ImageFolder(test_dir, transform=transform)\n",
    "\n",
    "class_indices = defaultdict(list)\n",
    "for idx, (_, label) in enumerate(full_dataset.samples):\n",
    "    class_indices[label].append(idx)\n",
    "\n",
    "# Stratified sampling\n",
    "rng = random.Random(RANDOM_SEED)\n",
    "train_indices = []\n",
    "val_indices = []\n",
    "\n",
    "for label, indices in class_indices.items():\n",
    "    rng.shuffle(indices)  # shuffle within each class\n",
    "    \n",
    "    n_total = len(indices)\n",
    "    n_train = int(SUBSET_FRACTION * n_total)\n",
    "    n_val = int(VAL_FRACTION * n_total)\n",
    "\n",
    "    # ensure at least 1 example per class\n",
    "    n_train = max(n_train, 1)\n",
    "    n_val = max(n_val, 1)\n",
    "\n",
    "    # Make sure we don't go out of bounds\n",
    "    available = indices[:n_train + n_val]\n",
    "    train_indices.extend(available[:n_train])\n",
    "    val_indices.extend(available[n_train:n_train + n_val])\n",
    "\n",
    "# Sort for reproducibility\n",
    "train_indices = sorted(train_indices)\n",
    "val_indices = sorted(val_indices)\n",
    "\n",
    "# Create subsets\n",
    "train_subset = Subset(full_dataset, train_indices)\n",
    "val_subset = Subset(full_dataset, val_indices)\n",
    "\n",
    "# DataLoaders\n",
    "train_loader = DataLoader(train_subset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "val_loader = DataLoader(val_subset, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf1af825",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10 - Loss: 10.8985 - Acc: 0.0010\n",
      "Epoch 2/10 - Loss: 3.7338 - Acc: 0.2844\n",
      "Epoch 3/10 - Loss: 2.5257 - Acc: 0.4950\n",
      "Epoch 4/10 - Loss: 1.8642 - Acc: 0.6040\n",
      "Epoch 5/10 - Loss: 1.4702 - Acc: 0.6835\n",
      "Epoch 6/10 - Loss: 1.1389 - Acc: 0.7480\n",
      "Epoch 7/10 - Loss: 0.9130 - Acc: 0.8041\n",
      "Epoch 8/10 - Loss: 0.7275 - Acc: 0.8446\n",
      "Epoch 9/10 - Loss: 0.5890 - Acc: 0.8777\n",
      "Epoch 10/10 - Loss: 0.4900 - Acc: 0.9046\n",
      "Model saved to vit_dino_finetuned.pth\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "import timm\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "num_classes = 200\n",
    "batch_size = 32\n",
    "epochs = 10\n",
    "lr = 0.001\n",
    "\n",
    "\n",
    "train_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "val_transform = transforms.Compose([\n",
    "    transforms.Resize(256),\n",
    "    transforms.CenterCrop(224),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5)),\n",
    "])\n",
    "\n",
    "\n",
    "model = timm.create_model('vit_small_patch16_224.dino', pretrained=True)\n",
    "\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "num_features = model.num_features \n",
    "\n",
    "model.head = nn.Linear(model.num_features, num_classes)\n",
    "for param in model.head.parameters():\n",
    "    param.requires_grad = True\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.head.parameters(), lr=lr)\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "    model.train()\n",
    "    total_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in val_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        \n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        total_loss += loss.item() * images.size(0)\n",
    "        _, predicted = outputs.max(1)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "        total += labels.size(0)\n",
    "\n",
    "    train_acc = correct / total\n",
    "    train_loss = total_loss / total\n",
    "    print(f\"Epoch {epoch+1}/{epochs} - Loss: {train_loss:.4f} - Acc: {train_acc:.4f}\")\n",
    "\n",
    "model.eval()\n",
    "\n",
    "model_path = \"vit_dino_finetuned.pth\"\n",
    "torch.save(model.state_dict(), model_path)\n",
    "print(f\"Model saved to {model_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "24d8edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_logit_lens_analysis(model=model, dataset=train_subset.dataset, device=device, cosine_path=\"logit_lens_results/DINO_lp/cosine_similarity.csv\", preds_path=\"logit_lens_results/DINO_lp/predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "710e38f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "distances = pd.read_csv(\"logit_lens_results/DINO_lp/cosine_similarity.csv\")\n",
    "predictions = pd.read_csv(\"logit_lens_results/DINO_lp/predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d889e41a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wb-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "03d6fe55",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/wb-env/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import clip\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import Compose, Resize, CenterCrop, ToTensor, Normalize\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from types import MethodType\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "57e54964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_vit_blocks(model):\n",
    "    original_blocks = model.visual.transformer.resblocks\n",
    "    activations = {}\n",
    "\n",
    "    for i, block in enumerate(original_blocks):\n",
    "        def make_custom_forward(orig_block, layer_name):\n",
    "            def custom_forward(self, x):\n",
    "                out = orig_block(x)\n",
    "                activations[layer_name] = out.clone()\n",
    "                return out\n",
    "            return custom_forward\n",
    "\n",
    "        block.forward = MethodType(make_custom_forward(block.forward, f\"layer_{i}\"), block)\n",
    "\n",
    "    return activations\n",
    "\n",
    "\n",
    "\n",
    "def logit_lens_analysis(activations, projection_head, ln_post, final_output, text_features, dictionary):\n",
    "    '''\n",
    "    Perform logit lens analysis on the activations\n",
    "    Returns:\n",
    "        - distances: cosine similarity to final output\n",
    "        - predictions: (predicted_label, similarity_score)\n",
    "    '''\n",
    "    distances = {}\n",
    "    predictions = {}\n",
    "\n",
    "    for name, x in activations.items():\n",
    "        # x shape: (seq_len, batch, dim)\n",
    "        x = x.permute(1, 0, 2)  # -> (batch, seq_len, dim)\n",
    "        cls_token = x[:, 0, :]  # take CLS token\n",
    "\n",
    "        # Apply final layer norm\n",
    "        cls_token = ln_post(cls_token)\n",
    "\n",
    "        # Project using CLIP's final projection matrix\n",
    "        projected = cls_token @ projection_head  # (1, 512)\n",
    "        projected = F.normalize(projected, dim=-1)\n",
    "\n",
    "        # Cosine similarity with final output\n",
    "        similarity = F.cosine_similarity(projected, final_output, dim=-1)\n",
    "        distances[name] = similarity.item()\n",
    "\n",
    "        # Cosine similarity with all text features\n",
    "        text_similarity = F.cosine_similarity(projected, text_features, dim=-1)\n",
    "        predicted_idx = torch.argmax(text_similarity).item()\n",
    "        predicted_label = dictionary[predicted_idx]\n",
    "        predicted_score = text_similarity[predicted_idx].item()\n",
    "\n",
    "        predictions[name] = (predicted_label, predicted_score)\n",
    "\n",
    "    return distances, predictions\n",
    "\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def perform_logit_lense_analysis(model, dataset, device):\n",
    "    idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}\n",
    "    model.eval()\n",
    "\n",
    "    # Utwórz folder na wyniki\n",
    "    os.makedirs(\"logit_lens_results\", exist_ok=True)\n",
    "\n",
    "    # Rejestracja hooków\n",
    "    activations = wrap_vit_blocks(model)\n",
    "    headers = sorted([f\"layer_{i}\" for i in range(len(model.visual.transformer.resblocks))], key=lambda x: int(x.split('_')[1]))\n",
    "\n",
    "    # Przygotuj pliki CSV z nagłówkami\n",
    "    cosine_path = \"logit_lens_results/cosine_similarity.csv\"\n",
    "    preds_path = \"logit_lens_results/predictions.csv\"\n",
    "\n",
    "    if not os.path.exists(cosine_path):\n",
    "        with open(cosine_path, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"Image\"] + headers)\n",
    "\n",
    "    if not os.path.exists(preds_path):\n",
    "        with open(preds_path, 'w', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow([\"Image\"] + [f\"{h}_label\" for h in headers] + [f\"{h}_prob\" for h in headers])\n",
    "\n",
    "    for image_idx, (image, label) in enumerate(dataset):\n",
    "        image = image.unsqueeze(0).to(device)\n",
    "        class_name = idx_to_class[label]\n",
    "        text = clip.tokenize([f\"a photo of a {class_name}\"]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            image_features = model.encode_image(image)\n",
    "            text_features = model.encode_text(text)\n",
    "\n",
    "        final_output = F.normalize(image_features, dim=-1)\n",
    "\n",
    "        distances, predictions = logit_lens_analysis(\n",
    "            activations,\n",
    "            model.visual.proj,\n",
    "            model.visual.ln_post,\n",
    "            final_output,\n",
    "            text_features,\n",
    "            idx_to_class  # słownik klas jako dictionary\n",
    "        )\n",
    "\n",
    "        # --- Zapis cosine similarity ---\n",
    "        cosine_row = [f\"Image_{image_idx + 1}\"] + [distances[layer] for layer in headers]\n",
    "        with open(cosine_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(cosine_row)\n",
    "\n",
    "        # --- Zapis predykcji i prawdopodobieństw ---\n",
    "        pred_labels = [predictions[layer][0] for layer in headers]\n",
    "        pred_probs = [predictions[layer][1] for layer in headers]\n",
    "        pred_row = [f\"Image_{image_idx + 1}\"] + pred_labels + pred_probs\n",
    "        with open(preds_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(pred_row)\n",
    "\n",
    "\n",
    "\n",
    "def plot_results(distances, predictions):\n",
    "    '''\n",
    "    Plots the results of the logit lens analysis\n",
    "    '''\n",
    "    layer_names = sorted(distances.keys(), key=lambda x: int(x.split('_')[1]))\n",
    "    similarity_values = [distances[layer] for layer in layer_names]\n",
    "    predicted_labels = [predictions[layer] for layer in layer_names]\n",
    "\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.heatmap(np.array(similarity_values).reshape(1, -1), annot=True, cmap=\"viridis\", xticklabels=layer_names, yticklabels=[\"Cosine Similarity\"], cbar_kws={'label': 'Cosine Similarity'}, cbar=True)\n",
    "\n",
    "    for i, label in enumerate(predicted_labels):\n",
    "        plt.text(i + 0.5, 0, label, ha='center', va='center', color='black', fontsize=10, rotation=90)\n",
    "\n",
    "    plt.title(\"Cosine Similarity Heatmap for Each Layer with Predictions\")\n",
    "    plt.xlabel(\"Layer\")\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "763b603c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Tiny ImageNet...\n",
      "Download and extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# URL i ścieżka tymczasowa\n",
    "url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "extract_path = \"./tiny-imagenet-200\"\n",
    "\n",
    "print(\"Downloading Tiny ImageNet...\")\n",
    "response = requests.get(url)\n",
    "with zipfile.ZipFile(BytesIO(response.content)) as zip_ref:\n",
    "    zip_ref.extractall(\".\")\n",
    "\n",
    "print(\"Download and extraction complete.\")\n",
    "\n",
    "\n",
    "train_dir = os.path.join(extract_path, \"train\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "                        std=[0.26862954, 0.26130258, 0.27577711]),\n",
    "])\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a7122",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load CLIP ViT model\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c6307d11",
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_logit_lense_analysis(model=model, dataset=train_dataset, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a434c6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wb-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

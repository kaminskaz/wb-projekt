{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "03d6fe55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import clip\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from types import MethodType\n",
    "import os\n",
    "import zipfile\n",
    "import requests\n",
    "from io import BytesIO\n",
    "from torchvision import datasets, transforms\n",
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "57e54964",
   "metadata": {},
   "outputs": [],
   "source": [
    "def wrap_vit_blocks(model):\n",
    "    original_blocks = model.visual.transformer.resblocks\n",
    "    activations = {}\n",
    "\n",
    "    for i, block in enumerate(original_blocks):\n",
    "        def make_custom_forward(orig_block, layer_name):\n",
    "            def custom_forward(self, x):\n",
    "                out = orig_block(x)\n",
    "                activations[layer_name] = out.clone()\n",
    "                return out\n",
    "            return custom_forward\n",
    "\n",
    "        block.forward = MethodType(make_custom_forward(block.forward, f\"layer_{i}\"), block)\n",
    "\n",
    "    return activations\n",
    "\n",
    "\n",
    "def logit_lens_analysis(activations, projection_head, ln_post, final_output, text_features, dictionary, temperature, top_k=5):\n",
    "    '''\n",
    "    Perform logit lens analysis on the activations\n",
    "    Returns:\n",
    "        - distances: cosine similarity to final output\n",
    "        - predictions: (predicted_label, similarity_score)\n",
    "    '''\n",
    "    distances = {}\n",
    "    predictions = {}\n",
    "\n",
    "    for name, x in activations.items():\n",
    "        # x shape: (seq_len, batch, dim)\n",
    "        x = x.permute(1, 0, 2)  # -> (batch, seq_len, dim)\n",
    "        cls_token = x[:, 0, :]  # take CLS token\n",
    "\n",
    "        # Apply final layer norm\n",
    "        cls_token = ln_post(cls_token)\n",
    "\n",
    "        # Project using CLIP's final projection matrix\n",
    "        projected = cls_token @ projection_head  # (1, 512)\n",
    "        projected = F.normalize(projected, dim=-1)\n",
    "\n",
    "        # Cosine similarity with final output\n",
    "        similarity = F.cosine_similarity(projected, final_output, dim=-1)\n",
    "        distances[name] = similarity.detach().cpu().numpy().tolist()[0]\n",
    "\n",
    "        # Cosine similarity with all text features\n",
    "        text_similarity = F.cosine_similarity(projected, text_features, dim=-1)\n",
    "        text_similarity = text_similarity * temperature\n",
    "        \n",
    "        all_probs = F.softmax(text_similarity, dim=-1)\n",
    "        top_k_probs, top_k_indices = torch.topk(all_probs, k=top_k)\n",
    "        \n",
    "        # top_k_values, top_k_indices = torch.topk(text_similarity, k=top_k)\n",
    "        # softmax_probs = F.softmax(top_k_values, dim=0)\n",
    "\n",
    "        # Predictions: collect the top-k predictions and their probabilities\n",
    "        top_k_predictions = []\n",
    "        for idx, prob in zip(top_k_indices, top_k_probs):\n",
    "            predicted_idx = idx.item()\n",
    "            predicted_label = dictionary[predicted_idx]\n",
    "            top_k_predictions.append((predicted_label, prob.item()))\n",
    "\n",
    "        predictions[name] = top_k_predictions\n",
    "\n",
    "    return distances, predictions\n",
    "\n",
    "\n",
    "import os\n",
    "import csv\n",
    "\n",
    "def perform_logit_lense_analysis(model, dataset, device):\n",
    "    idx_to_class = {v: k for k, v in dataset.class_to_idx.items()}\n",
    "    model.eval()\n",
    "\n",
    "    # Utwórz folder na wyniki\n",
    "    os.makedirs(\"logit_lens_results\", exist_ok=True)\n",
    "\n",
    "    # Rejestracja hooków\n",
    "    activations = wrap_vit_blocks(model)\n",
    "    headers = sorted([f\"layer_{i}\" for i in range(len(model.visual.transformer.resblocks))], key=lambda x: int(x.split('_')[1]))\n",
    "\n",
    "    # Przygotuj pliki CSV z nagłówkami\n",
    "    cosine_path = \"logit_lens_results/cosine_similarity.csv\"\n",
    "    preds_path = \"logit_lens_results/predictions.csv\"\n",
    "\n",
    "    all_classes = [f\"a photo of a {idx_to_class[i]}\" for i in range(len(idx_to_class))]\n",
    "    text_tokens_all = clip.tokenize(all_classes).to(device)\n",
    "    with torch.no_grad():\n",
    "        all_text_features = model.encode_text(text_tokens_all)\n",
    "        all_text_features = F.normalize(all_text_features, dim=-1)\n",
    "\n",
    "    for image_idx, (image, label) in enumerate(dataset):\n",
    "        image = image.unsqueeze(0).to(device)\n",
    "        # class_name = idx_to_class[label]\n",
    "        # text = clip.tokenize([f\"a photo of a {class_name}\"]).to(device)\n",
    "\n",
    "        with torch.no_grad():\n",
    "            image_features = model.encode_image(image)\n",
    "            # text_features = model.encode_text(text)\n",
    "\n",
    "        final_output = F.normalize(image_features, dim=-1)\n",
    "\n",
    "        distances, predictions = logit_lens_analysis(\n",
    "            activations,\n",
    "            model.visual.proj,\n",
    "            model.visual.ln_post,\n",
    "            final_output,\n",
    "            all_text_features,\n",
    "            idx_to_class, \n",
    "            model.logit_scale.exp()\n",
    "        )\n",
    "\n",
    "        # --- Zapis cosine similarity ---\n",
    "        cosine_row = [f\"Image_{image_idx + 1}\"] + [distances[layer] for layer in headers]\n",
    "        with open(cosine_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(cosine_row)\n",
    "\n",
    "        # --- Zapis predykcji i prawdopodobieństw ---\n",
    "        pred_labels = [predictions[layer][0][0] for layer in headers]  # label from top-1\n",
    "        pred_probs = [predictions[layer][0][1] for layer in headers]  # prob from top-1\n",
    "        pred_row = [f\"Image_{image_idx + 1}\"] + pred_labels + pred_probs\n",
    "        with open(preds_path, 'a', newline='') as f:\n",
    "            writer = csv.writer(f)\n",
    "            writer.writerow(pred_row)\n",
    "\n",
    "\n",
    "def plot_results(distances, predictions):\n",
    "    '''\n",
    "    Plots cosine similarity and prediction probabilities for each layer\n",
    "    '''\n",
    "    layer_names = sorted(distances.keys(), key=lambda x: int(x.split('_')[1]))\n",
    "    \n",
    "    similarity_values = [distances[layer] for layer in layer_names]\n",
    "    prob_values = [predictions.get(f\"{layer}_prob\", np.nan) for layer in layer_names]  # fallback if missing\n",
    "    predicted_labels = [predictions.get(f\"{layer}_label\", \"\") for layer in layer_names]\n",
    "\n",
    "    fig, axes = plt.subplots(2, 1, figsize=(12, 6), gridspec_kw={'height_ratios': [1, 1]})\n",
    "\n",
    "    sns.heatmap(np.array(similarity_values).reshape(1, -1), annot=True, cmap=\"viridis\",\n",
    "                xticklabels=layer_names, yticklabels=[\"Cosine Similarity\"], cbar=True,\n",
    "                ax=axes[0], cbar_kws={'label': 'Cosine Similarity'})\n",
    "\n",
    "    sns.heatmap(np.array(prob_values).reshape(1, -1), annot=True, cmap=\"magma\",\n",
    "                xticklabels=layer_names, yticklabels=[\"Prediction Prob.\"], cbar=True,\n",
    "                ax=axes[1], cbar_kws={'label': 'Prediction Probability'})\n",
    "\n",
    "    for i, label in enumerate(predicted_labels):\n",
    "        axes[1].text(i + 0.5, -0.3, label, ha='center', va='center', color='black', fontsize=9, rotation=90, transform=axes[1].transData)\n",
    "\n",
    "    plt.suptitle(\"Cosine Similarity & Prediction Probability per Layer\", fontsize=14)\n",
    "    plt.tight_layout(rect=[0, 0, 1, 0.95])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "763b603c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading Tiny ImageNet...\n",
      "Download and extraction complete.\n"
     ]
    }
   ],
   "source": [
    "# URL i ścieżka tymczasowa\n",
    "url = \"http://cs231n.stanford.edu/tiny-imagenet-200.zip\"\n",
    "extract_path = \"./tiny-imagenet-200\"\n",
    "\n",
    "print(\"Downloading Tiny ImageNet...\")\n",
    "response = requests.get(url)\n",
    "with zipfile.ZipFile(BytesIO(response.content)) as zip_ref:\n",
    "    zip_ref.extractall(\".\")\n",
    "\n",
    "print(\"Download and extraction complete.\")\n",
    "\n",
    "\n",
    "train_dir = os.path.join(extract_path, \"train\")\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)), \n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.48145466, 0.4578275, 0.40821073],\n",
    "                        std=[0.26862954, 0.26130258, 0.27577711]),\n",
    "])\n",
    "train_dataset = datasets.ImageFolder(train_dir, transform=transform)\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a7122",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "# Load CLIP ViT model\n",
    "model, preprocess = clip.load(\"ViT-B/32\", device=device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "24d8edc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "perform_logit_lense_analysis(model=model, dataset=train_dataset, device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "710e38f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "distances = pd.read_csv(\"logit_lens_results/cosine_similarity.csv\")\n",
    "predictions = pd.read_csv(\"logit_lens_results/predictions.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a434c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_results(distances.iloc[100001, :].drop(\"Image\", errors=\"ignore\"), predictions.iloc[100001,:].drop(\"Image\", errors=\"ignore\"))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "wb-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
